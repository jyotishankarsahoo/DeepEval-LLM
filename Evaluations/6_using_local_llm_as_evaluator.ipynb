{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385d1919",
   "metadata": {},
   "source": [
    "#### Preload Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f2b1d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2268f",
   "metadata": {},
   "source": [
    "#### Configure Deepeval to use Ollama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93a7e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings updated for this session. To persist, use --\u001b[33msave\u001b[0m=\u001b[35mdotenv\u001b[0m\u001b[1m[\u001b[0m:path\u001b[1m]\u001b[0m \u001b[1m(\u001b[0mdefault\n",
      ".env.local\u001b[1m)\u001b[0m or set \u001b[33mDEEPEVAL_DEFAULT_SAVE\u001b[0m=\u001b[35mdotenv\u001b[0m:.env.local\n",
      "ðŸ™Œ Congratulations! You're now using a local Ollama model `deepseek-r\u001b[1;92m1:8b\u001b[0m` for \n",
      "all evals that require an LLM.\n"
     ]
    }
   ],
   "source": [
    "!deepeval set-ollama deepseek-r1:8b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36b65f",
   "metadata": {},
   "source": [
    "#### Use Ollama to evaluate llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "254844f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using deepseek-r</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">1:8b</span><span style=\"color: #374151; text-decoration-color: #374151\"> </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing deepseek-r\u001b[0m\u001b[1;38;2;55;65;81m1:8b\u001b[0m\u001b[38;2;55;65;81m \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/jyotisahoo/VScode_Project/DeepEval-LLM/venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/jyotisahoo/VScode_Project/DeepEval-LLM/venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: deepseek-r1:8b (Ollama), reason: The score is 1.00 because there are no irrelevant statements in the actual output, so the answer is perfectly relevant despite the JSON being empty., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is the capital of France?\n",
      "  - actual output: Paris\n",
      "  - expected output: The capital of France is Paris.\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
       "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
       "Â» \u001b]8;id=953938;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Done ðŸŽ‰! View results on \n",
       "<a href=\"https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3hcp5x0295o70gs3bsiqvr/regression-testing\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3hcp5x0295o70gs3bsiqvr/regression-testi</span></a>\n",
       "<a href=\"https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3hcp5x0295o70gs3bsiqvr/regression-testing\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">ng</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Done ðŸŽ‰! View results on \n",
       "\u001b]8;id=335935;https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3hcp5x0295o70gs3bsiqvr/regression-testing\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3hcp5x0295o70gs3bsiqvr/regression-testi\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b]8;id=335935;https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3hcp5x0295o70gs3bsiqvr/regression-testing\u001b\\\u001b[4;94mng\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Answer Relevancy', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because there are no irrelevant statements in the actual output, so the answer is perfectly relevant despite the JSON being empty.', strict_mode=False, evaluation_model='deepseek-r1:8b (Ollama)', error=None, evaluation_cost=0.0, verbose_logs='Statements:\\n[\\n    \"Paris\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], conversational=False, multimodal=False, input='What is the capital of France?', actual_output='Paris', expected_output='The capital of France is Paris.', context=None, retrieval_context=None, turns=None, additional_metadata=None)], confident_link='https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3hcp5x0295o70gs3bsiqvr/regression-testing', test_run_id='cmi3hcp5x0295o70gs3bsiqvr')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.evaluate import evaluate\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What is the capital of France?\",\n",
    "    actual_output=\"Paris\",\n",
    "    expected_output=\"The capital of France is Paris.\"\n",
    "    )\n",
    "evaluate(test_cases=[test_case], metrics=[AnswerRelevancyMetric()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51770e9a",
   "metadata": {},
   "source": [
    "#### Setting up Model and Base URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43700774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using deepseek-r</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">1:8b</span><span style=\"color: #374151; text-decoration-color: #374151\"> </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing deepseek-r\u001b[0m\u001b[1;38;2;55;65;81m1:8b\u001b[0m\u001b[38;2;55;65;81m \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/jyotisahoo/VScode_Project/DeepEval-LLM/venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/jyotisahoo/VScode_Project/DeepEval-LLM/venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: deepseek-r1:8b (Ollama), reason: The score is 1.00 because there are no irrelevant statements in the actual output, so the answer is perfectly relevant despite the JSON being empty., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is the capital of France?\n",
      "  - actual output: Paris\n",
      "  - expected output: The capital of France is Paris.\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">âš  WARNING:</span> No hyperparameters logged.\n",
       "Â» <a href=\"https://deepeval.com/docs/evaluation-prompts\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Log hyperparameters</span></a> to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33mâš  WARNING:\u001b[0m No hyperparameters logged.\n",
       "Â» \u001b]8;id=721164;https://deepeval.com/docs/evaluation-prompts\u001b\\\u001b[1;34mLog hyperparameters\u001b[0m\u001b]8;;\u001b\\ to attribute prompts and models to your test runs.\n",
       "\n",
       "================================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Done ðŸŽ‰! View results on \n",
       "<a href=\"https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3fvvy709chmk0gofd4v8nv/regression-testing\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3fvvy709chmk0gofd4v8nv/regression-testi</span></a>\n",
       "<a href=\"https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3fvvy709chmk0gofd4v8nv/regression-testing\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">ng</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Done ðŸŽ‰! View results on \n",
       "\u001b]8;id=42183;https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3fvvy709chmk0gofd4v8nv/regression-testing\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3fvvy709chmk0gofd4v8nv/regression-testi\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b]8;id=42183;https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3fvvy709chmk0gofd4v8nv/regression-testing\u001b\\\u001b[4;94mng\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Answer Relevancy', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because there are no irrelevant statements in the actual output, so the answer is perfectly relevant despite the JSON being empty.', strict_mode=False, evaluation_model='deepseek-r1:8b (Ollama)', error=None, evaluation_cost=0.0, verbose_logs='Statements:\\n[\\n    \"Paris\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], conversational=False, multimodal=False, input='What is the capital of France?', actual_output='Paris', expected_output='The capital of France is Paris.', context=None, retrieval_context=None, turns=None, additional_metadata=None)], confident_link='https://app.confident-ai.com/project/cmhz4xrfc001jmn0gk9ti0ck5/test-runs/cmi3fvvy709chmk0gofd4v8nv/regression-testing', test_run_id='cmi3fvvy709chmk0gofd4v8nv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.evaluate import evaluate, AsyncConfig\n",
    "from deepeval.models import OllamaModel\n",
    "\n",
    "ollama_model = OllamaModel(\n",
    "    model=\"deepseek-r1:8b\",\n",
    "    base_url=\"http://localhost:11434\" \n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What is the capital of France?\",\n",
    "    actual_output=\"Paris\",\n",
    "    expected_output=\"The capital of France is Paris.\"\n",
    "    )\n",
    "metric = AnswerRelevancyMetric(\n",
    "    model=ollama_model\n",
    ")\n",
    "evaluate(test_cases=[test_case], \n",
    "         metrics=[metric], \n",
    "         async_config=AsyncConfig(run_async=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
